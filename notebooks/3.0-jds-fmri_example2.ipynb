{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fMRI example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from os.path import join\n",
    "import glob\n",
    "import pandas as pd\n",
    "import tensorflow as tf \n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def center_normalize(x):\n",
    "    x_mean_rows = np.mean(x,1).reshape(x.shape[0],1)\n",
    "    x_std_rows = np.std(x,1).reshape(x.shape[0],1)\n",
    "    return (x - x_mean_rows) / x_std_rows\n",
    "\n",
    "def onehot(y):\n",
    "    ynp=np.array(y)\n",
    "    y_onehot=[0]*len(ynp)\n",
    "    for i,j in enumerate(ynp):\n",
    "        y_onehot[i]=[0]*ynp.max()\n",
    "        y_onehot[i][j-1]=1\n",
    "        \n",
    "    return y_onehot\n",
    "\n",
    "def model_svm(x_train,y_train,x_test,y_test):\n",
    "    C = 1  # SVM regularization parameter\n",
    "    svc = svm.LinearSVC(C=C).fit(x_train, y_train)\n",
    "    y_pred = svc.predict(x_test)\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "def model_tf_regression(x_train,y_train,x_test,y_test):\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.InteractiveSession()\n",
    "\n",
    "    x = tf.placeholder(tf.float32, shape=[None, x_train.shape[1]])\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "\n",
    "\n",
    "    W = tf.Variable(tf.zeros([x_train.shape[1],3]))\n",
    "    b = tf.Variable(tf.zeros([3]))\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    y = tf.matmul(x,W) + b\n",
    "\n",
    "    cross_entropy = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "    \n",
    "    ##train\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "    for i in range(1000):\n",
    "        train_step.run(feed_dict={x: x_train.tolist(), y_: onehot(y_train)})\n",
    "    \n",
    "    #tf.argmax gives an index of the highest entry in a tensor along some axis\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "\n",
    "    #we can take this list of booleans and calculate the fraction correct\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    return accuracy.eval(feed_dict={x: x_test.tolist(), y_: onehot(y_test)})\n",
    "    sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def model_tf_nn(x_train,y_train,x_test,y_test):\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    n_inputs = x_train.shape[1]\n",
    "    n_hidden1 = 10\n",
    "    n_outputs = 3\n",
    "    learning_rate = 0.01\n",
    "\n",
    "\n",
    "    def neuron_layer(X, n_neurons, name, activation=None):\n",
    "        with tf.name_scope(name):\n",
    "            n_inputs = int(X.get_shape()[1])\n",
    "            stddev = 1 / np.sqrt(n_inputs)\n",
    "            init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
    "            W = tf.Variable(init, name=\"weights\")\n",
    "            b = tf.Variable(tf.zeros([n_neurons]), name=\"biases\")\n",
    "            Z = tf.matmul(X, W) + b\n",
    "            if activation==\"relu\":\n",
    "                return tf.nn.relu(Z)\n",
    "            else:\n",
    "                return Z\n",
    "    X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "    y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
    "\n",
    "    with tf.name_scope(\"dnn\"):\n",
    "        hidden1 = neuron_layer(X, n_hidden1, \"hidden1\", activation=\"relu\")\n",
    "        logits = neuron_layer(hidden1, n_outputs, \"output\")\n",
    "\n",
    "    with tf.name_scope(\"loss\"):\n",
    "        xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "        loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "    with tf.name_scope(\"train\"):\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "        training_op = optimizer.minimize(loss)\n",
    "\n",
    "    with tf.name_scope(\"eval\"):\n",
    "        correct = tf.nn.in_top_k(logits, y, 1)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    n_epochs = 50\n",
    "    acc_test_high = 0.0\n",
    "\n",
    "    sess = tf.InteractiveSession()\n",
    "\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        for i in range(x_train.shape[0]):\n",
    "            x_data = x_train[i,:].reshape([1,x_train.shape[1]])\n",
    "            y_data = np.array([y_train[i]])\n",
    "            sess.run(training_op, feed_dict={X: x_data, y: y_data })\n",
    "        acc_train = accuracy.eval(feed_dict={X: x_train, y: y_train})\n",
    "        acc_test = accuracy.eval(feed_dict={X: x_test, y: y_test})\n",
    "        if acc_test > acc_test_high:\n",
    "            acc_test_high = acc_test\n",
    "#         print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)\n",
    "\n",
    "    # save_path = saver.save(sess, \"./one_layer.ckpt\")\n",
    "    return acc_test_high\n",
    "    sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data dir test \n",
    "data_dir = '../data/greco_mri'\n",
    "behav_dir = '../data/greco_behav'\n",
    "\n",
    "#rois\n",
    "rois = ['left_CA1','right_CA1','left_DG','right_DG'];\n",
    "\n",
    "#subjec list\n",
    "subjects = ['S1_A','S2_B','S3_A','S4_A','S5_A','S6_A','S7_A','S8_B',\n",
    "            'S9_A','S10_B','S11_B','S12_B','S13_B','S14_B','S15_B',\n",
    "            'S16_A','S21_B','S22_B','S24_A'];\n",
    "subjects = np.array(subjects);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores_svm = np.empty((subjects.shape[0],4))\n",
    "scores_reg = np.empty((subjects.shape[0],4))\n",
    "scores_nn = np.empty((subjects.shape[0],4))\n",
    "for i,subj in enumerate(subjects):\n",
    "    for run in [0,1,2,3]:\n",
    "       \n",
    "        behav = pd.read_table(join(behav_dir,subj,subj + '.txt'))\n",
    "\n",
    "        fname = join(data_dir,subj + '_right_DG.csv')\n",
    "        betas= pd.read_csv(fname,header=None)\n",
    "\n",
    "        test_ind   = behav['run_num'] == run\n",
    "        train_ind  = behav['run_num'] != run\n",
    "        y_test     = behav['currCity'][test_ind].as_matrix()\n",
    "        \n",
    "        y_test_r = np.empty(y_test.shape)\n",
    "        y_test_r[y_test == 1] = 0\n",
    "        y_test_r[y_test == 2] = 1\n",
    "        y_test_r[y_test == 3] = 2\n",
    "        y_train    = behav['currCity'][train_ind].as_matrix()\n",
    "        \n",
    "        y_train_r = np.empty(y_train.shape)\n",
    "        y_train_r[y_train == 1] = 0\n",
    "        y_train_r[y_train == 2] = 1\n",
    "        y_train_r[y_train == 3] = 2\n",
    "        x_test = center_normalize(betas[test_ind].as_matrix())\n",
    "        x_train = center_normalize(betas[train_ind].as_matrix())\n",
    "        scores_svm[i,run]=model_svm(x_train,y_train,x_test,y_test)\n",
    "        scores_reg[i,run] = model_tf_regression(x_train,y_train,x_test,y_test)\n",
    "        scores_nn[i,run] = model_tf_nn(x_train,y_train_r,x_test,y_test_r)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression (mean accuracy): 0.324736842788\n",
      "SVM (mean accuracy): 0.324736842105\n",
      "Neural network (mean accuracy): 0.395789474837\n"
     ]
    }
   ],
   "source": [
    "print('Logistic regression (mean accuracy): ' + str(np.mean(scores_reg)))\n",
    "print('SVM (mean accuracy): ' + str(np.mean(scores_svm)))\n",
    "print('Neural network (mean accuracy): ' + str(np.mean(scores_nn)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression (1samp ttest):\n",
      "Ttest_1sampResult(statistic=-0.30706705741261137, pvalue=0.76231644869561455)\n",
      "\n",
      "SVM (1samp ttest):\n",
      "Ttest_1sampResult(statistic=-0.35242936701678962, pvalue=0.72860912450487225)\n",
      "\n",
      "Neural network (1samp ttest)\n",
      "Ttest_1sampResult(statistic=5.0932099220274942, pvalue=7.5913412853404732e-05)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "print('Logistic regression (1samp ttest):')\n",
    "print(stats.ttest_1samp(np.mean(scores_reg,1),.33))\n",
    "print\n",
    "print('SVM (1samp ttest):')     \n",
    "print(stats.ttest_1samp(np.mean(scores_svm,1),.33))\n",
    "print\n",
    "print('Neural network (1samp ttest)')\n",
    "print(stats.ttest_1samp(np.mean(scores_nn,1),.33))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
