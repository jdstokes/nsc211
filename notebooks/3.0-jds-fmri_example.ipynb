{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fMRI example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from os.path import join\n",
    "import glob\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def center_normalize(x):\n",
    "    return (x - np.mean(x)) / np.std(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data dir test \n",
    "data_dir = '../data/greco_mri'\n",
    "behav_dir = '../data/greco_behav'\n",
    "\n",
    "#rois\n",
    "rois = ['left_CA1','right_CA1','left_DG','right_DG'];\n",
    "\n",
    "#subjec list\n",
    "subjects = ['S1_A','S2_B','S3_A','S4_A','S5_A','S6_A','S7_A','S8_B',\n",
    "            'S9_A','S10_B','S11_B','S12_B','S13_B','S14_B','S15_B',\n",
    "            'S16_A','S21_B','S22_B','S23_B','S24_A'];\n",
    "\n",
    "voxel_cutoff = 130;\n",
    "\n",
    "subjects = np.array(subjects);\n",
    "\n",
    "\n",
    "# does tf want a list or tuple?\n",
    "data_y = [];\n",
    "data_x = [];\n",
    "data_y_TEST = [];\n",
    "data_x_TEST = [];\n",
    "\n",
    "sub_rand_idx = np.random.permutation(20);\n",
    "subjects_train = subjects[sub_rand_idx[0:-1]]\n",
    "subjects_test  = [subjects[sub_rand_idx[-1]]];\n",
    "\n",
    "num_voxels = np.empty(subjects_train.shape)\n",
    "num_trials = np.empty(subjects_train.shape)\n",
    "\n",
    "\n",
    "for i,subj in enumerate(subjects_train):\n",
    "    fname = join(data_dir,subj + '_right_DG.csv')\n",
    "    betas= pd.read_csv(fname,header=None)\n",
    "    behav = pd.read_table(join(behav_dir,subj,subj + '.txt'))\n",
    "#     idx = np.random.permutation(100);\n",
    "    idx = np.array(range(0,voxel_cutoff))\n",
    "\n",
    "    for j in range(0,betas.shape[0]):\n",
    " \n",
    "        data_x.append(center_normalize(betas.iloc[j,idx].values))\n",
    "        data_y.append(behav['currCity'][j])\n",
    "    num_trials[i] = betas.shape[0];\n",
    "    num_voxels[i] = betas.shape[1];\n",
    " \n",
    "for i,subj in enumerate(subjects_test):\n",
    "    fname = join(data_dir,subj + '_right_DG.csv')\n",
    "    betas= pd.read_csv(fname,header=None)\n",
    "    behav = pd.read_table(join(behav_dir,subj,subj + '.txt'))\n",
    "    idx = np.array(range(0,voxel_cutoff))\n",
    "\n",
    "    for j in range(0,betas.shape[0]):\n",
    "\n",
    "        data_x_TEST.append(center_normalize(betas.iloc[j,idx].values))\n",
    "        data_y_TEST.append(behav['currCity'][j])\n",
    "\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum number of voxels: 142.0\n",
      "number of trials per subject: 99.9473684211\n",
      "number of subjects: 19\n"
     ]
    }
   ],
   "source": [
    "print('minimum number of voxels: ' + str(np.min(num_voxels)))\n",
    "print('number of trials per subject: ' + str(np.mean(num_trials)))\n",
    "print('number of subjects: ' + str(len(subjects_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "ynp=np.array(data_y)\n",
    "data_y_onehot=[0]*len(ynp)\n",
    "for i,j in enumerate(ynp):\n",
    "    data_y_onehot[i]=[0]*ynp.max()\n",
    "    data_y_onehot[i][j-1]=1\n",
    "    \n",
    "    \n",
    "# one hot encoding\n",
    "ynp=np.array(data_y_TEST)\n",
    "data_y_TEST_onehot=[0]*len(ynp)\n",
    "for i,j in enumerate(ynp):\n",
    "    data_y_TEST_onehot[i]=[0]*ynp.max()\n",
    "    data_y_TEST_onehot[i][j-1]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X_train, X_valid, Y_train, Y_valid = train_test_split(data_x, data_y_onehot, \n",
    "#                                                     test_size=0.2, \n",
    "#                                                     stratify=data_y_onehot)\n",
    "\n",
    "X_train = data_x;\n",
    "Y_train = data_y_onehot;\n",
    "\n",
    "X_valid = data_x_TEST;\n",
    "Y_valid = data_y_TEST_onehot;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, voxel_cutoff])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "\n",
    "\n",
    "W = tf.Variable(tf.zeros([voxel_cutoff,3]))\n",
    "b = tf.Variable(tf.zeros([3]))\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "y = tf.matmul(x,W) + b\n",
    "\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.31 s, sys: 251 ms, total: 5.56 s\n",
      "Wall time: 4.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "\n",
    "for i in range(1000):\n",
    "    train_step.run(feed_dict={x: X_train, y_: Y_train})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32\n"
     ]
    }
   ],
   "source": [
    "#tf.argmax gives an index of the highest entry in a tensor along some axis\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "\n",
    "#we can take this list of booleans and calculate the fraction correct\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "#print the accuracy\n",
    "print(accuracy.eval(feed_dict={x: X_valid, y_: Y_valid}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's build a multilayer convolutional network\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, train accuracy = 37.60%, test accuracy = 35.00%\n",
      "Epoch = 2, train accuracy = 39.44%, test accuracy = 33.00%\n",
      "Epoch = 3, train accuracy = 39.86%, test accuracy = 33.00%\n",
      "Epoch = 4, train accuracy = 40.55%, test accuracy = 30.00%\n",
      "Epoch = 5, train accuracy = 41.34%, test accuracy = 31.00%\n",
      "Epoch = 6, train accuracy = 42.02%, test accuracy = 30.00%\n",
      "Epoch = 7, train accuracy = 42.92%, test accuracy = 30.00%\n",
      "Epoch = 8, train accuracy = 43.44%, test accuracy = 32.00%\n",
      "Epoch = 9, train accuracy = 44.39%, test accuracy = 30.00%\n",
      "Epoch = 10, train accuracy = 45.44%, test accuracy = 29.00%\n",
      "Epoch = 11, train accuracy = 46.55%, test accuracy = 30.00%\n",
      "Epoch = 12, train accuracy = 48.29%, test accuracy = 30.00%\n",
      "Epoch = 13, train accuracy = 49.97%, test accuracy = 29.00%\n",
      "Epoch = 14, train accuracy = 51.45%, test accuracy = 28.00%\n",
      "Epoch = 15, train accuracy = 54.13%, test accuracy = 30.00%\n",
      "Epoch = 16, train accuracy = 56.40%, test accuracy = 30.00%\n",
      "Epoch = 17, train accuracy = 59.35%, test accuracy = 30.00%\n",
      "Epoch = 18, train accuracy = 63.24%, test accuracy = 32.00%\n",
      "Epoch = 19, train accuracy = 67.35%, test accuracy = 31.00%\n",
      "Epoch = 20, train accuracy = 71.09%, test accuracy = 31.00%\n",
      "Epoch = 21, train accuracy = 76.57%, test accuracy = 32.00%\n",
      "Epoch = 22, train accuracy = 80.25%, test accuracy = 33.00%\n",
      "Epoch = 23, train accuracy = 85.52%, test accuracy = 36.00%\n",
      "Epoch = 24, train accuracy = 88.63%, test accuracy = 38.00%\n",
      "Epoch = 25, train accuracy = 92.00%, test accuracy = 38.00%\n",
      "Epoch = 26, train accuracy = 94.05%, test accuracy = 36.00%\n",
      "Epoch = 27, train accuracy = 95.26%, test accuracy = 37.00%\n",
      "Epoch = 28, train accuracy = 96.74%, test accuracy = 37.00%\n",
      "Epoch = 29, train accuracy = 97.63%, test accuracy = 36.00%\n",
      "Epoch = 30, train accuracy = 98.42%, test accuracy = 33.00%\n",
      "Epoch = 31, train accuracy = 99.05%, test accuracy = 33.00%\n",
      "Epoch = 32, train accuracy = 99.63%, test accuracy = 31.00%\n",
      "Epoch = 33, train accuracy = 99.79%, test accuracy = 31.00%\n",
      "Epoch = 34, train accuracy = 99.84%, test accuracy = 32.00%\n",
      "Epoch = 35, train accuracy = 99.84%, test accuracy = 32.00%\n",
      "Epoch = 36, train accuracy = 99.95%, test accuracy = 30.00%\n",
      "Epoch = 37, train accuracy = 99.95%, test accuracy = 30.00%\n",
      "Epoch = 38, train accuracy = 99.95%, test accuracy = 29.00%\n",
      "Epoch = 39, train accuracy = 100.00%, test accuracy = 29.00%\n",
      "Epoch = 40, train accuracy = 100.00%, test accuracy = 28.00%\n",
      "Epoch = 41, train accuracy = 100.00%, test accuracy = 27.00%\n",
      "Epoch = 42, train accuracy = 100.00%, test accuracy = 27.00%\n",
      "Epoch = 43, train accuracy = 100.00%, test accuracy = 27.00%\n",
      "Epoch = 44, train accuracy = 100.00%, test accuracy = 26.00%\n",
      "Epoch = 45, train accuracy = 100.00%, test accuracy = 26.00%\n",
      "Epoch = 46, train accuracy = 100.00%, test accuracy = 26.00%\n",
      "Epoch = 47, train accuracy = 100.00%, test accuracy = 26.00%\n",
      "Epoch = 48, train accuracy = 100.00%, test accuracy = 26.00%\n",
      "Epoch = 49, train accuracy = 100.00%, test accuracy = 26.00%\n",
      "Epoch = 50, train accuracy = 100.00%, test accuracy = 26.00%\n",
      "Epoch = 51, train accuracy = 100.00%, test accuracy = 28.00%\n",
      "Epoch = 52, train accuracy = 100.00%, test accuracy = 28.00%\n",
      "Epoch = 53, train accuracy = 100.00%, test accuracy = 28.00%\n",
      "Epoch = 54, train accuracy = 100.00%, test accuracy = 28.00%\n",
      "Epoch = 55, train accuracy = 100.00%, test accuracy = 28.00%\n",
      "Epoch = 56, train accuracy = 100.00%, test accuracy = 28.00%\n",
      "Epoch = 57, train accuracy = 100.00%, test accuracy = 29.00%\n",
      "Epoch = 58, train accuracy = 100.00%, test accuracy = 28.00%\n",
      "Epoch = 59, train accuracy = 100.00%, test accuracy = 28.00%\n",
      "Epoch = 60, train accuracy = 100.00%, test accuracy = 28.00%\n",
      "Epoch = 61, train accuracy = 100.00%, test accuracy = 28.00%\n",
      "Epoch = 62, train accuracy = 100.00%, test accuracy = 28.00%\n",
      "Epoch = 63, train accuracy = 100.00%, test accuracy = 28.00%\n",
      "Epoch = 64, train accuracy = 100.00%, test accuracy = 27.00%\n",
      "Epoch = 65, train accuracy = 100.00%, test accuracy = 27.00%\n",
      "Epoch = 66, train accuracy = 100.00%, test accuracy = 27.00%\n",
      "Epoch = 67, train accuracy = 100.00%, test accuracy = 27.00%\n",
      "Epoch = 68, train accuracy = 100.00%, test accuracy = 27.00%\n",
      "Epoch = 69, train accuracy = 100.00%, test accuracy = 28.00%\n",
      "Epoch = 70, train accuracy = 100.00%, test accuracy = 28.00%\n",
      "Epoch = 71, train accuracy = 100.00%, test accuracy = 28.00%\n",
      "Epoch = 72, train accuracy = 100.00%, test accuracy = 28.00%\n",
      "Epoch = 73, train accuracy = 100.00%, test accuracy = 27.00%\n",
      "Epoch = 74, train accuracy = 100.00%, test accuracy = 27.00%\n",
      "Epoch = 75, train accuracy = 100.00%, test accuracy = 27.00%\n",
      "Epoch = 76, train accuracy = 100.00%, test accuracy = 27.00%\n",
      "Epoch = 77, train accuracy = 100.00%, test accuracy = 27.00%\n",
      "Epoch = 78, train accuracy = 100.00%, test accuracy = 27.00%\n",
      "Epoch = 79, train accuracy = 100.00%, test accuracy = 27.00%\n",
      "Epoch = 80, train accuracy = 100.00%, test accuracy = 27.00%\n",
      "Epoch = 81, train accuracy = 100.00%, test accuracy = 27.00%\n",
      "Epoch = 82, train accuracy = 100.00%, test accuracy = 27.00%\n",
      "Epoch = 83, train accuracy = 100.00%, test accuracy = 27.00%\n",
      "Epoch = 84, train accuracy = 100.00%, test accuracy = 27.00%\n",
      "Epoch = 85, train accuracy = 100.00%, test accuracy = 27.00%\n",
      "Epoch = 86, train accuracy = 100.00%, test accuracy = 27.00%\n",
      "Epoch = 87, train accuracy = 100.00%, test accuracy = 27.00%\n",
      "Epoch = 88, train accuracy = 100.00%, test accuracy = 26.00%\n",
      "Epoch = 89, train accuracy = 100.00%, test accuracy = 26.00%\n",
      "Epoch = 90, train accuracy = 100.00%, test accuracy = 26.00%\n",
      "Epoch = 91, train accuracy = 100.00%, test accuracy = 26.00%\n",
      "Epoch = 92, train accuracy = 100.00%, test accuracy = 26.00%\n",
      "Epoch = 93, train accuracy = 100.00%, test accuracy = 26.00%\n",
      "Epoch = 94, train accuracy = 100.00%, test accuracy = 26.00%\n",
      "Epoch = 95, train accuracy = 100.00%, test accuracy = 26.00%\n",
      "Epoch = 96, train accuracy = 100.00%, test accuracy = 26.00%\n",
      "Epoch = 97, train accuracy = 100.00%, test accuracy = 26.00%\n",
      "Epoch = 98, train accuracy = 100.00%, test accuracy = 26.00%\n",
      "Epoch = 99, train accuracy = 100.00%, test accuracy = 26.00%\n",
      "Epoch = 100, train accuracy = 100.00%, test accuracy = 26.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def init_weights(shape):\n",
    "    \"\"\" Weight initialization \"\"\"\n",
    "    weights = tf.random_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(weights)\n",
    "\n",
    "def forwardprop(X, w_1, w_2):\n",
    "    \"\"\"\n",
    "    Forward-propagation.\n",
    "    IMPORTANT: yhat is not softmax since TensorFlow's softmax_cross_entropy_with_logits() does that internally.\n",
    "    \"\"\"\n",
    "    h    = tf.nn.sigmoid(tf.matmul(X, w_1))  # The \\sigma function\n",
    "    yhat = tf.matmul(h, w_2)  # The \\varphi function\n",
    "    return yhat\n",
    "\n",
    "\n",
    "# Layer's sizes\n",
    "x_size = voxel_cutoff   \n",
    "h_size = 256               \n",
    "y_size = 3  \n",
    "\n",
    "# Symbols\n",
    "X = tf.placeholder(\"float\", shape=[None, x_size])\n",
    "y = tf.placeholder(\"float\", shape=[None, y_size])\n",
    "\n",
    "# Weight initializations\n",
    "w_1 = init_weights((x_size, h_size))\n",
    "w_2 = init_weights((h_size, y_size))\n",
    "\n",
    "# Forward propagation\n",
    "yhat    = forwardprop(X, w_1, w_2)\n",
    "predict = tf.argmax(yhat, axis=1)\n",
    "\n",
    "# Backward propagation\n",
    "cost    = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=yhat))\n",
    "updates = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "\n",
    "# Run SGD\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for epoch in range(100):\n",
    "    # Train with each example\n",
    "    for i in range(len(X_train)):\n",
    "        sess.run(updates, feed_dict={X: X_train[i: i + 1], y: Y_train[i: i + 1]})\n",
    "\n",
    "    train_accuracy = np.mean(np.argmax(Y_train, axis=1) ==\n",
    "                             sess.run(predict, feed_dict={X: X_train, y: Y_train}))\n",
    "    test_accuracy  = np.mean(np.argmax(Y_valid, axis=1) ==\n",
    "                             sess.run(predict, feed_dict={X: X_valid, y: Y_valid}))\n",
    "\n",
    "    print(\"Epoch = %d, train accuracy = %.2f%%, test accuracy = %.2f%%\"\n",
    "          % (epoch + 1, 100. * train_accuracy, 100. * test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
