{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First graph in TensorFlow\n",
    "- tf.reset_default_graph\n",
    "- tf.Variable\n",
    "    - Variable.name property: maps to the name of the mutable Tensor in which that variable is stored\n",
    "    - Important for saving and restoring variables\n",
    "    - Tensorboard uses these names\n",
    "    - Relevant for TensorFlow namespace organization (i.e. scope)\n",
    "    - \"You can imagine Python namespace and TensorFlow namespace as two parallel universes. Names in TensorFlow space are actually the \"real\" attributes belonging to any TensorFlow variables, while names in Python space are just temporary pointers pointing to TensorFlow variables during this run of your script. That is the reason why when saving and restoring variables, only TensorFlow names are used, because the Python namespace no longer exists after script being terminated, but Tensorflow namespace is still there in your saved files.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lee's checking balance:-130\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()#important for tensorboard when using jupyter notebook\n",
    "\n",
    "students = tf.Variable(13, name=\"students\") \n",
    "coffee = tf.Variable(-10, name=\"coffee\") \n",
    "lees_checking = students*coffee\n",
    "\n",
    "#one way to do it but pretty verbose\n",
    "sess = tf.Session() \n",
    "sess.run(students.initializer)\n",
    "sess.run(coffee.initializer)\n",
    "result = sess.run(lees_checking)\n",
    "print(\"Lee's checking balance:\" + str(result))\n",
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-130\n"
     ]
    }
   ],
   "source": [
    "#but this is better\n",
    "with tf.Session() as sess: \n",
    "    students.initializer.run() \n",
    "    coffee.initializer.run() \n",
    "    result = lees_checking.eval()\n",
    "    print(result)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do a lil bit better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-130\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "students = tf.Variable(13, name=\"students\") \n",
    "coffee = tf.Variable(-10, name=\"coffee\") \n",
    "lees_checking = students*coffee\n",
    "init = tf.global_variables_initializer() # prepare an init node\n",
    "with tf.Session() as sess:\n",
    "    init.run() # actually initialize all the variables\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 9)\n",
      "0.111111111111\n",
      "[  1.00000000e+00   6.60969987e-17   5.50808322e-18   6.60969987e-17\n",
      "  -1.06030602e-16  -1.10161664e-17   3.44255201e-18  -1.07958431e-15\n",
      "  -8.52651283e-15]\n",
      "[ 0.38915536  0.36424355  0.5116157  ..., -0.06612179 -0.06360587\n",
      "  0.01359031]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_housing_data = scaler.fit_transform(housing.data)\n",
    "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]\n",
    "\n",
    "print(scaled_housing_data_plus_bias.shape)\n",
    "print(scaled_housing_data_plus_bias.mean())\n",
    "print(scaled_housing_data_plus_bias.mean(axis=0))\n",
    "print(scaled_housing_data_plus_bias.mean(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Normal Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.06856298]\n",
      " [ 0.82961965]\n",
      " [ 0.11875178]\n",
      " [-0.26552707]\n",
      " [ 0.30569667]\n",
      " [-0.00450281]\n",
      " [-0.03932635]\n",
      " [-0.8998825 ]\n",
      " [-0.87053877]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
    "with tf.Session() as sess: \n",
    "    theta_value = theta.eval()\n",
    "    print(theta_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Batch gradient descent with manually computed gradients**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch', 0, 'MSE =', 7.4496336)\n",
      "('Epoch', 100, 'MSE =', 7.4496336)\n",
      "('Epoch', 200, 'MSE =', 7.4496336)\n",
      "('Epoch', 300, 'MSE =', 7.4496336)\n",
      "('Epoch', 400, 'MSE =', 7.4496336)\n",
      "('Epoch', 500, 'MSE =', 7.4496336)\n",
      "('Epoch', 600, 'MSE =', 7.4496336)\n",
      "('Epoch', 700, 'MSE =', 7.4496336)\n",
      "('Epoch', 800, 'MSE =', 7.4496336)\n",
      "('Epoch', 900, 'MSE =', 7.4496336)\n",
      "[[ 2.06856298]\n",
      " [ 0.82961965]\n",
      " [ 0.11875178]\n",
      " [-0.26552707]\n",
      " [ 0.30569667]\n",
      " [-0.00450281]\n",
      " [-0.03932635]\n",
      " [-0.8998825 ]\n",
      " [-0.87053877]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "# all the data, batch gradient descent\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer() \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch%100==0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "        \n",
    "    best_theta = theta.eval()\n",
    "\n",
    "print(theta_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Batch gradient descent with using autodiff**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch', 0, 'MSE =', 2.7544272)\n",
      "('Epoch', 100, 'MSE =', 0.63222194)\n",
      "('Epoch', 200, 'MSE =', 0.5727796)\n",
      "('Epoch', 300, 'MSE =', 0.55850053)\n",
      "('Epoch', 400, 'MSE =', 0.54906934)\n",
      "('Epoch', 500, 'MSE =', 0.54228771)\n",
      "('Epoch', 600, 'MSE =', 0.53737879)\n",
      "('Epoch', 700, 'MSE =', 0.53382188)\n",
      "('Epoch', 800, 'MSE =', 0.53124273)\n",
      "('Epoch', 900, 'MSE =', 0.52937055)\n",
      "Best theta:\n",
      "[[  2.06855249e+00]\n",
      " [  7.74078071e-01]\n",
      " [  1.31192386e-01]\n",
      " [ -1.17845066e-01]\n",
      " [  1.64778143e-01]\n",
      " [  7.44078017e-04]\n",
      " [ -3.91945094e-02]\n",
      " [ -8.61356676e-01]\n",
      " [ -8.23479772e-01]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "# all the data, batch gradient descent\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "gradients = tf.gradients(mse, [theta])[0]\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()\n",
    "print(\"Best theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient Descent with Optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch', 0, 'MSE =', 2.7544272)\n",
      "('Epoch', 100, 'MSE =', 0.63222194)\n",
      "('Epoch', 200, 'MSE =', 0.5727796)\n",
      "('Epoch', 300, 'MSE =', 0.55850053)\n",
      "('Epoch', 400, 'MSE =', 0.54906934)\n",
      "('Epoch', 500, 'MSE =', 0.54228771)\n",
      "('Epoch', 600, 'MSE =', 0.53737879)\n",
      "('Epoch', 700, 'MSE =', 0.53382188)\n",
      "('Epoch', 800, 'MSE =', 0.53124273)\n",
      "('Epoch', 900, 'MSE =', 0.52937055)\n",
      "Best theta:\n",
      "[[  2.06855249e+00]\n",
      " [  7.74078071e-01]\n",
      " [  1.31192386e-01]\n",
      " [ -1.17845066e-01]\n",
      " [  1.64778143e-01]\n",
      " [  7.44078017e-04]\n",
      " [ -3.91945094e-02]\n",
      " [ -8.61356676e-01]\n",
      " [ -8.23479772e-01]]\n",
      "CPU times: user 2.47 s, sys: 173 ms, total: 2.64 s\n",
      "Wall time: 1.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tf.reset_default_graph()\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()\n",
    "print(\"Best theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feeding data\n",
    "**Setting up placeholder nodes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.  7.  8.]]\n",
      "[[  9.  10.  11.]\n",
      " [ 12.  13.  14.]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "A = tf.placeholder(tf.float32, shape=(None, 3))\n",
    "B = A + 5\n",
    "with tf.Session() as sess:\n",
    "    B_val_1 = B.eval(feed_dict={A: [[1, 2, 3]]})\n",
    "    B_val_2 = B.eval(feed_dict={A: [[4, 5, 6], [7, 8, 9]]})\n",
    "\n",
    "print(B_val_1)\n",
    "print(B_val_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mini-batch Gradient Descent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my mini batch method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best theta:\n",
      "[[  2.06602192e+00]\n",
      " [  8.30935359e-01]\n",
      " [  1.26624838e-01]\n",
      " [ -2.78939813e-01]\n",
      " [  2.79391229e-01]\n",
      " [  7.06658990e-04]\n",
      " [ -3.94885316e-02]\n",
      " [ -8.93702090e-01]\n",
      " [ -8.75018418e-01]]\n",
      "CPU times: user 1min 57s, sys: 19.7 s, total: 2min 16s\n",
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Batch parameters\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "batch_index =0\n",
    "rnd.seed(42)\n",
    "indices = rnd.randint(m,size=m)\n",
    "mb_indices = np.array_split(indices,n_batches)\n",
    "\n",
    "\n",
    "#Construction phase (Our graph again)\n",
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#Execution phase \n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_inds in mb_indices:\n",
    "            X_batch = scaled_housing_data_plus_bias[batch_inds]\n",
    "            y_batch = housing.target.reshape(-1, 1)[batch_inds]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "    best_theta = theta.eval()\n",
    "print(\"Best theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "another mini batch method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best theta:\n",
      "[[ 2.0614748 ]\n",
      " [ 0.82204753]\n",
      " [ 0.12198913]\n",
      " [-0.26323745]\n",
      " [ 0.32637092]\n",
      " [-0.01081076]\n",
      " [-0.06751335]\n",
      " [-0.90269727]\n",
      " [-0.8744489 ]]\n",
      "CPU times: user 2min 6s, sys: 19.6 s, total: 2min 26s\n",
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    rnd.seed(epoch * n_batches + batch_index)\n",
    "    indices = rnd.randint(m, size=batch_size)\n",
    "    X_batch = scaled_housing_data_plus_bias[indices]\n",
    "    y_batch = housing.target.reshape(-1, 1)[indices]\n",
    "    return X_batch, y_batch\n",
    "\n",
    "n_epochs = 1000\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "    best_theta = theta.eval()\n",
    "print(\"Best theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## saving and restoring "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch', 0, 'MSE =', 2.7544272)\n",
      "('Epoch', 100, 'MSE =', 0.63222194)\n",
      "('Epoch', 200, 'MSE =', 0.5727796)\n",
      "('Epoch', 300, 'MSE =', 0.55850053)\n",
      "('Epoch', 400, 'MSE =', 0.54906934)\n",
      "('Epoch', 500, 'MSE =', 0.54228771)\n",
      "('Epoch', 600, 'MSE =', 0.53737879)\n",
      "('Epoch', 700, 'MSE =', 0.53382188)\n",
      "('Epoch', 800, 'MSE =', 0.53124273)\n",
      "('Epoch', 900, 'MSE =', 0.52937055)\n",
      "Best theta:\n",
      "[[  2.06855249e+00]\n",
      " [  7.74078071e-01]\n",
      " [  1.31192386e-01]\n",
      " [ -1.17845066e-01]\n",
      " [  1.64778143e-01]\n",
      " [  7.44078017e-04]\n",
      " [ -3.91945094e-02]\n",
      " [ -8.61356676e-01]\n",
      " [ -8.23479772e-01]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "            save_path = saver.save(sess, \"/tmp/my_model.ckpt\")\n",
    "        sess.run(training_op)\n",
    "   \n",
    "    best_theta = theta.eval()\n",
    "    save_path = saver.save(sess, \"my_model_final.ckpt\")\n",
    "\n",
    "print(\"Best theta:\")\n",
    "print(best_theta)\n",
    "\n",
    "tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "206\n",
      "216\n",
      "226\n",
      "236\n",
      "246\n",
      "256\n",
      "266\n",
      "276\n",
      "286\n",
      "296\n",
      "306\n",
      "316\n",
      "326\n",
      "336\n",
      "346\n",
      "356\n",
      "366\n",
      "376\n",
      "386\n",
      "396\n",
      "406\n",
      "412\n",
      "422\n",
      "432\n",
      "442\n",
      "452\n",
      "462\n",
      "472\n",
      "482\n",
      "492\n",
      "502\n",
      "512\n",
      "522\n",
      "532\n",
      "542\n",
      "552\n",
      "562\n",
      "572\n",
      "582\n",
      "592\n",
      "602\n",
      "612\n",
      "618\n",
      "628\n",
      "638\n",
      "648\n",
      "658\n",
      "668\n",
      "678\n",
      "688\n",
      "698\n",
      "708\n",
      "718\n",
      "728\n",
      "738\n",
      "748\n",
      "758\n",
      "768\n",
      "778\n",
      "788\n",
      "798\n",
      "808\n",
      "818\n",
      "824\n",
      "834\n",
      "844\n",
      "854\n",
      "864\n",
      "874\n",
      "884\n",
      "894\n",
      "904\n",
      "914\n",
      "924\n",
      "934\n",
      "944\n",
      "954\n",
      "964\n",
      "974\n",
      "984\n",
      "994\n",
      "1004\n",
      "1014\n",
      "1024\n",
      "Best theta:\n",
      "[[ 2.07962132]\n",
      " [ 0.76063615]\n",
      " [ 0.13567705]\n",
      " [-0.13422588]\n",
      " [ 0.17423598]\n",
      " [-0.01030065]\n",
      " [-0.01802275]\n",
      " [-0.87352598]\n",
      " [-0.82851851]]\n",
      "CPU times: user 1.29 s, sys: 190 ms, total: 1.48 s\n",
      "Wall time: 1.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "'''Time stamp log directory'''\n",
    "#if you don't use a different log directory every time you run the program\n",
    "# TensorBoard will merge stats from different runs\n",
    "\n",
    "from datetime import datetime\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "\n",
    "'''Hyper parameters'''\n",
    "learning_rate = 0.01\n",
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "'''Construction phase'''\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#FOR TENSORBOARD\n",
    "#The first line creates a node in the graph that evaluatees the MSE value and writes it\n",
    "#to the tensorboard log string called a 'summary'. The second line creates a FileWriter \n",
    "# that we'll use to write summaries to logfiles.\n",
    "# logdir : path of log directory\n",
    "#  tf.get_default_graph() : graph you want to visualize. optional\n",
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "# merged = tf.summary.merge_all()\n",
    "train_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                train_writer.add_summary(summary_str, step)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "    best_theta = theta.eval()\n",
    "\n",
    "train_writer.flush()\n",
    "train_writer.close()\n",
    "print(\"Best theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9 % 10 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:datasci]",
   "language": "python",
   "name": "conda-env-datasci-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
